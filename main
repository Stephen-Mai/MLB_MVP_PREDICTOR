import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Define AL and NL teams
AL_TEAMS = ['BAL', 'BOS', 'CWS', 'CLE', 'DET', 'HOU', 'KC', 'LAA', 'MIN', 'NYY', 'OAK', 'SEA', 'TB', 'TEX', 'TOR']
NL_TEAMS = ['ARI', 'ATL', 'CHC', 'CIN', 'COL', 'LAD', 'MIA', 'MIL', 'NYM', 'PHI', 'PIT', 'SD', 'SF', 'STL', 'WSH']

def load_and_preprocess_data(file_path):
    """
    Load and preprocess the MLB player data.
    """
    print("Loading and preprocessing data...")
    # Load the data
    df = pd.read_csv(file_path)
    
    # Remove any rows with NaN values
    df = df.dropna()
    
    # Add league information based on team
    df['League'] = df['Team'].apply(lambda x: 'AL' if x in AL_TEAMS else 'NL')
    
    # Filter out players with fewer than 100 games or 300 at-bats
    # These thresholds typically represent significant playing time needed for MVP consideration
    df = df[df['G'] >= 100]
    df = df[df['AB'] >= 300]
    
    # Convert percentage stats to float if they're strings
    for col in ['AVG', 'OBP', 'SLG', 'OPS']:
        if df[col].dtype == 'object':
            df[col] = df[col].astype(float)
    
    return df

def engineer_features(df):
    """
    Engineer additional features that may be predictive of MVP status.
    """
    print("Engineering features...")
    
    # Calculate Total Bases (TB)
    df['TB'] = df['H'] + df['2B'] + (2 * df['3B']) + (3 * df['HR'])
    
    # Calculate additional power metrics
    df['PowerScore'] = (df['HR'] * 1.5) + (df['2B'] * 0.3) + (df['3B'] * 0.7) + (df['SLG'] * 100)
    df['RunCreation'] = (df['R'] * 0.6) + (df['RBI'] * 0.4)  # Weighted run creation
    
    # Calculate Run Production (R + RBI)
    df['RunProd'] = df['R'] + df['RBI']
    
    # Calculate per-game metrics
    df['HR_per_G'] = df['HR'] / df['G']
    df['RBI_per_G'] = df['RBI'] / df['G']
    df['R_per_G'] = df['R'] / df['G']
    df['H_per_G'] = df['H'] / df['G']
    df['TB_per_G'] = df['TB'] / df['G']
    df['RunProd_per_G'] = df['RunProd'] / df['G']
    df['SB_per_G'] = df['SB'] / df['G']
    
    # Calculate per-AB metrics
    df['HR_per_AB'] = df['HR'] / df['AB']
    df['TB_per_AB'] = df['TB'] / df['AB']
    
    # Calculate plate discipline metrics
    df['BB_per_PA'] = df['BB'] / (df['AB'] + df['BB'] + df['HBP'] + df['SF'])
    df['BB_to_SO'] = df['BB'] / df['SO']
    
    # Create interaction features
    df['OPS_RunProd'] = df['OPS'] * df['RunProd']
    df['AVG_TB'] = df['AVG'] * df['TB']
    df['SLG_HR'] = df['SLG'] * df['HR']
    df['OBP_SB'] = df['OBP'] * df['SB']
    
    # Create a "star power" composite metric - adjusted to emphasize power hitting
    df['StarPower'] = (df['OPS'] * 150) + (df['HR'] * 5) + (df['RBI'] * 2) + (df['R']) + (df['SB'])
    
    # Add positional value factor (C and SS are more valuable defensively)
    position_value = {
        'C': 1.2,  # Catchers get a boost
        'SS': 1.15,  # Shortstops get a boost
        '2B': 1.1,  # Second basemen get a boost
        '3B': 1.05,  # Third basemen get a small boost
        'OF': 1.0,  # Outfielders are baseline
        '1B': 0.95,  # First basemen get a small penalty
        'DH': 0.9  # DHs get a penalty
    }
    
    # Adjust for position - extract first position for multi-position players
    df['PosValue'] = df['Pos'].apply(lambda x: position_value.get(x.split(',')[0], 1.0))
    df['StarPower_Adjusted'] = df['StarPower'] * df['PosValue']
    
    # Create features that reflect team performance context
    # In the absence of team record data, we use player's stats relative to league
    
    return df

def create_historical_mvp_labels():
    """
    Create historical MVP labels for training. In a real scenario, you would have historical MVP data.
    For this example, we'll create synthetic MVP labels based on top OPS + RBI players.
    """
    # This is a placeholder function. In a real implementation, you would use actual historical MVP results.
    # For demonstration purposes only - creating synthetic MVP labels is not ideal
    mvps = {
        # Format: 'Year-League': 'Player'
        '2023-AL': 'Aaron Judge',
        '2022-AL': 'Aaron Judge',
        '2021-AL': 'Shohei Ohtani',
        '2020-AL': 'Jose Abreu',
        '2019-AL': 'Mike Trout',
        '2023-NL': 'Ronald Acuna',
        '2022-NL': 'Paul Goldschmidt',
        '2021-NL': 'Bryce Harper',
        '2020-NL': 'Freddie Freeman',
        '2019-NL': 'Cody Bellinger'
    }
    return mvps

def prepare_model_data(df, features):
    """
    Prepare data for modeling, including scaling numerical features.
    """
    print("Preparing model data...")
    
    # Select only relevant features for the model
    X = df[features].copy()
    
    # Normalize the features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
    
    # In a full implementation, we would use historical MVP data
    # For demonstration, we'll create a proxy for MVPs using exceptional performance
    # This is a simplification - real MVP voting is more complex
    
    # Calculate a composite score - heavily weighted toward power numbers and OPS
    df['MVP_Score'] = (
        (df['OPS'] * 0.35) +              # Increased OPS weight
        (df['HR'] * 0.007) +              # Added direct HR count (not per game)
        (df['HR_per_G'] * 0.15) +         # Still keep HR per game but reduced
        (df['RBI'] * 0.005) +             # Added direct RBI count
        (df['RunProd_per_G'] * 0.15) +    # Reduced run production per game
        (df['TB_per_G'] * 0.15) +         # Kept total bases the same
        (df['SB_per_G'] * 0.03) +         # Reduced stolen base importance
        (df['PowerScore'] * 0.0015) +     # Added power score
        (df['BB_to_SO'] * 0.05) +         # Added plate discipline
        (df['PosValue'] * 0.02)           # Reduced positional adjustment
    )
    
    # Identify top MVP candidates - using more restrictive thresholds to be more selective
    al_threshold = df[df['League'] == 'AL']['MVP_Score'].quantile(0.97)  # More selective threshold
    nl_threshold = df[df['League'] == 'NL']['MVP_Score'].quantile(0.97)  # More selective threshold
    
    # Give extra boost to players with exceptional OPS (like Judge's 1.159)
    # This helps identify truly dominant seasons
    ops_exceptional = 1.000  # OPS threshold for exceptional seasons
    df.loc[(df['OPS'] >= ops_exceptional) & (df['HR'] >= 40), 'MVP_Score'] *= 1.2  # 20% boost
    
    df['MVP_Candidate'] = 0
    df.loc[(df['League'] == 'AL') & (df['MVP_Score'] >= al_threshold), 'MVP_Candidate'] = 1
    df.loc[(df['League'] == 'NL') & (df['MVP_Score'] >= nl_threshold), 'MVP_Candidate'] = 1
    
    return X_scaled, df['MVP_Candidate'], scaler

def train_model(X, y):
    """
    Train a Gradient Boosting Classifier to predict MVP candidates.
    Uses SMOTE to handle class imbalance.
    """
    print("Training the model...")
    
    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # Apply SMOTE to handle class imbalance
    print("Applying SMOTE to handle class imbalance...")
    try:
        smote = SMOTE(random_state=42)
        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
        print(f"Original class distribution: {np.bincount(y_train)}")
        print(f"Resampled class distribution: {np.bincount(y_train_resampled)}")
    except ValueError as e:
        print(f"SMOTE error: {e}. Using original data.")
        X_train_resampled, y_train_resampled = X_train, y_train
    
    # Create and train the model with optimized parameters - tuned for MVP prediction
    model = GradientBoostingClassifier(
        n_estimators=300,           # Increased for better precision
        learning_rate=0.03,         # Decreased for better generalization
        max_depth=5,                # Increased for more complex relationships
        min_samples_split=4,        # Adjusted
        min_samples_leaf=2,         # Kept the same
        subsample=0.85,             # Slightly increased
        max_features='sqrt',        # Kept the same
        random_state=42
    )
    
    model.fit(X_train_resampled, y_train_resampled)
    
    # Evaluate the model
    train_preds = model.predict(X_train)
    test_preds = model.predict(X_test)
    
    print(f"Training accuracy: {accuracy_score(y_train, train_preds):.4f}")
    print(f"Testing accuracy: {accuracy_score(y_test, test_preds):.4f}")
    
    # Print precision, recall, and F1 score (better metrics for imbalanced classification)
    precision, recall, f1, _ = precision_recall_fscore_support(y_test, test_preds, average='binary')
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    
    # Print feature importances
    importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)
    print("\nFeature Importances:")
    print(importances.head(10))
    
    return model

def predict_mvp_candidates(df, model, features, scaler):
    """
    Predict MVP candidates for the current season and return top candidates by league.
    """
    print("Predicting MVP candidates...")
    
    # Prepare the features
    X = df[features].copy()
    X_scaled = scaler.transform(X)
    
    # Get predictions and probabilities
    df['MVP_Probability'] = model.predict_proba(X_scaled)[:, 1]
    
    # Apply additional logic to favor exceptionally dominant offensive seasons
    # This helps ensure players like Judge with historic seasons rise to the top
    df.loc[(df['OPS'] > 1.100) & (df['HR'] > 50), 'MVP_Probability'] = 1.0      # Truly elite seasons
    df.loc[(df['OPS'] > 1.000) & (df['HR'] > 40), 'MVP_Probability'] *= 1.15    # Outstanding seasons
    df.loc[(df['RBI'] > 130), 'MVP_Probability'] *= 1.1                         # Elite RBI production
    
    # Get all candidates with at least 0.1% chance
    threshold = 0.001  # minimum chance to be considered
    al_all = df[df['League'] == 'AL'].sort_values('MVP_Probability', ascending=False)
    nl_all = df[df['League'] == 'NL'].sort_values('MVP_Probability', ascending=False)
    
    # Filter to candidates with meaningful chances
    al_candidates = al_all[al_all['MVP_Probability'] >= threshold].copy()
    nl_candidates = nl_all[nl_all['MVP_Probability'] >= threshold].copy()
    
    # Normalize probabilities to sum to 100% within each league
    if not al_candidates.empty:
        al_sum = al_candidates['MVP_Probability'].sum()
        al_candidates['MVP_Percentage'] = (al_candidates['MVP_Probability'] / al_sum) * 100
        al_candidates['MVP_Percentage'] = al_candidates['MVP_Percentage'].round(1)  # Round to 1 decimal place
    
    if not nl_candidates.empty:
        nl_sum = nl_candidates['MVP_Probability'].sum()
        nl_candidates['MVP_Percentage'] = (nl_candidates['MVP_Probability'] / nl_sum) * 100
        nl_candidates['MVP_Percentage'] = nl_candidates['MVP_Percentage'].round(1)  # Round to 1 decimal place
    
    # Display results
    print("\nAmerican League MVP Candidates:")
    display_candidates_with_percentages(al_candidates.head(10))
    
    print("\nNational League MVP Candidates:")
    display_candidates_with_percentages(nl_candidates.head(10))
    
    return al_candidates.head(10), nl_candidates.head(10)

def display_candidates(candidates):
    """
    Display the top MVP candidates in a readable format.
    """
    display_cols = ['Player', 'Team', 'Pos', 'G', 'AVG', 'HR', 'RBI', 'R', 'SB', 'OPS', 'MVP_Probability']
    print(candidates[display_cols].to_string(index=False, float_format=lambda x: f"{x:.3f}"))

def display_candidates_with_percentages(candidates):
    """
    Display the top MVP candidates with normalized percentages.
    """
    if 'MVP_Percentage' not in candidates.columns:
        display_candidates(candidates)
        return
        
    display_cols = ['Player', 'Team', 'Pos', 'G', 'AVG', 'HR', 'RBI', 'R', 'SB', 'OPS', 'MVP_Percentage']
    
    # Format percentage with % sign
    formatted_candidates = candidates[display_cols].copy()
    formatted_candidates['MVP_Percentage'] = formatted_candidates['MVP_Percentage'].apply(lambda x: f"{x:.1f}%")
    
    print(formatted_candidates.to_string(index=False))

def plot_top_candidates(al_candidates, nl_candidates):
    """
    Create visualizations of the top MVP candidates with normalized percentages.
    """
    plt.figure(figsize=(14, 12))
    plt.style.use('ggplot')  # More attractive style
    
    # Filter to only include players with meaningful MVP chances (at least 1%)
    if 'MVP_Percentage' in al_candidates.columns:
        al_significant = al_candidates[al_candidates['MVP_Percentage'] >= 1.0].copy()
        al_significant = al_significant.sort_values('MVP_Percentage', ascending=True)  # For horizontal plot
        
        # AL MVP Percentage
        plt.subplot(2, 1, 1)
        bars = plt.barh(al_significant['Player'], al_significant['MVP_Percentage'], 
                     color='royalblue', alpha=0.7)
        plt.xlabel('Chance to Win AL MVP (%)', fontsize=12)
        plt.title('2024 American League MVP Race', fontsize=16, fontweight='bold')
        plt.xlim(0, min(100, al_significant['MVP_Percentage'].max() * 1.1))  # max plus 10% padding
        plt.gca().invert_yaxis()
        
        # Add percentage labels to the end of each bar
        for bar in bars:
            width = bar.get_width()
            label_x_pos = width + 1  # 1% padding
            plt.text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{width:.1f}%',
                  va='center', fontsize=10)
    else:
        plt.subplot(2, 1, 1)
        plt.text(0.5, 0.5, "No significant AL MVP candidates found", 
              horizontalalignment='center', verticalalignment='center')
    
    # Filter NL candidates similarly
    if 'MVP_Percentage' in nl_candidates.columns:
        nl_significant = nl_candidates[nl_candidates['MVP_Percentage'] >= 1.0].copy()
        nl_significant = nl_significant.sort_values('MVP_Percentage', ascending=True)  # For horizontal plot
        
        # NL MVP Percentage
        plt.subplot(2, 1, 2)
        bars = plt.barh(nl_significant['Player'], nl_significant['MVP_Percentage'],
                     color='firebrick', alpha=0.7)
        plt.xlabel('Chance to Win NL MVP (%)', fontsize=12)
        plt.title('2024 National League MVP Race', fontsize=16, fontweight='bold')
        plt.xlim(0, min(100, nl_significant['MVP_Percentage'].max() * 1.1))  # max plus 10% padding
        plt.gca().invert_yaxis()
        
        # Add percentage labels
        for bar in bars:
            width = bar.get_width()
            label_x_pos = width + 1  # 1% padding
            plt.text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{width:.1f}%',
                  va='center', fontsize=10)
    else:
        plt.subplot(2, 1, 2)
        plt.text(0.5, 0.5, "No significant NL MVP candidates found", 
              horizontalalignment='center', verticalalignment='center')
    
    plt.tight_layout()
    plt.savefig('/Users/stephenmai/Downloads/mvp_candidates_2024_percentages.png', dpi=300)
    print("\nVisualization saved as '/Users/stephenmai/Downloads/mvp_candidates_2024_percentages.png'")

def main():
    """
    Main function to run the MVP prediction model.
    """
    # Load and preprocess the data
    file_path = '/Users/stephenmai/Downloads/mlb-player-stats-Batters2024.csv'
    data = load_and_preprocess_data(file_path)
    
    # Engineer features
    data = engineer_features(data)
    
    # Define the features to use in the model - prioritizing power numbers and MVP voting patterns
    model_features = [
        'OPS',                # Primary rate stat - highly valued in MVP voting
        'HR',                 # Raw HR count - crucial for MVP voting
        'RBI',                # Raw RBI count - crucial for MVP voting
        'R',                  # Raw run count
        'TB_per_G',           # Total bases per game - good all-around measure
        'PowerScore',         # Custom power metric
        'RunCreation',        # Custom run creation metric
        'SLG',                # Slugging percentage - power indicator
        'OBP',                # On-base percentage - plate discipline indicator
        'G',                  # Games played - durability factor
        'StarPower_Adjusted', # Star power with positional adjustment
        'HR_per_G',           # HR per game - rate stat
        'RunProd_per_G',      # Run production per game - rate stat
        'OPS_RunProd',        # Interaction between OPS and run production
        'SLG_HR',             # Interaction between SLG and HR
        'BB_to_SO',           # Plate discipline
        'SB',                 # Stolen bases - lower priority
        'AVG'                 # Batting average - traditional but less important
    ]
    
    # Prepare data for modeling
    X_scaled, y, scaler = prepare_model_data(data, model_features)
    
    # Train the model
    model = train_model(X_scaled, y)
    
    # Predict MVP candidates
    al_candidates, nl_candidates = predict_mvp_candidates(data, model, model_features, scaler)
    
    # Plot the results
    plot_top_candidates(al_candidates, nl_candidates)

if __name__ == "__main__":
    main()
